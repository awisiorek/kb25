{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b687fe",
   "metadata": {},
   "source": [
    "# Übungsaufgaben 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46783823",
   "metadata": {},
   "source": [
    "## Aufgabe 1: xmlpos (Extraktion und Annotation von TEI-XML)\n",
    "Schreiben Sie ein Python-Programm `xmlpos`, das aus einer Korpusdatei\n",
    "den Dokumenteninhalt extrahiert, diesen dann satzweise POS-tagged\n",
    "und eine XML-Datei folgender Form ausgibt:\n",
    "\n",
    "```xml\n",
    "<doc>\n",
    "  <s id=\"s-0001\">\n",
    "    <w id=\"w-0001\" pos=\"DET\">Der</w>\n",
    "\t<w id=\"w-0002\" pos=\"NOUN\">Hase</w>\n",
    "\t...\n",
    "  </s>\n",
    "  <s id=\"s-0002\">\n",
    "  ...\n",
    "</doc>\n",
    "```\n",
    "\n",
    "Anmerkungen:\n",
    "* Verwenden Sie die [TEI](https://tei-c.org/)-kodierten Korpusdateien des [deutschen Textarchivs](https://www.deutschestextarchiv.de/), z.B:\n",
    "  * Altman 1890: https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890\n",
    "  * Brandes 1832: https://www.deutschestextarchiv.de/book/download_xml/brandes_naturlehre03_1832\n",
    "\n",
    "\n",
    "> _XML-TEI (Text Encoding Initiative): weit verbreitetes XML-Dokumentenformat für die Kodierung von Textkorpora_    \n",
    "  (Schema mit einheitlichen Elementnamen und Attributen für die editionswissenschaftliche und linguistische Annotation von Texten, u.a. über DTD definiert)\n",
    "\n",
    "> _DTA (Deutsches Textarchiv): historisches deutsches Korpus_ (linguistisch annotiertes Volltextkorpus deutschsprachiger Texte aus der Zeit um 1600 bis 1900)\n",
    "      \n",
    "\n",
    "* Sie können die XML-Dateien auch mit Werkzeugen wie wget oder curl\n",
    "  (man-Pages!)  herunterladen, oder auch Pythons `urllib` verwenden\n",
    "* Sie können `nltk` zur Satzsegmentierung und zum POS-Tagging verwenden; alternativ\n",
    "  dazu können Sie auch _stanza_ (oder _[spacy](https://spacy.io/)_) verwenden\n",
    "* Stellen Sie sicher, dass der tatsächlichen Text aus den Dokumenten extrahiert wird;\n",
    "  betrachten Sie hierzu folgendes (valides) XML-Dokument: `<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>` \n",
    "\n",
    "\n",
    "```xml\n",
    " <a>\n",
    "\t<b>\n",
    "\t\t1\n",
    "\t\t<c>\n",
    "\t\t\t2\n",
    "\t\t\t<d/>\n",
    "\t\t\t3\n",
    "\t\t</c>\n",
    "\t</b>\n",
    "\t4\n",
    "\t<lb/>\n",
    "\t5\n",
    "</a> \n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07675d6b",
   "metadata": {},
   "source": [
    "#### *weiterführende Informationen:*\n",
    "\n",
    "* [F-Strings](http://cissandbox.bentley.edu/sandbox/wp-content/uploads/2022-02-10-Documentation-on-f-strings-Updated.pdf)\n",
    "* [Spacy](https://spacy.io/)\n",
    "* [DTA](https://www.deutschestextarchiv.de/)\n",
    "* [TEI](https://github.com/TEIC/TEI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669632d",
   "metadata": {},
   "source": [
    "### Vorgehen:\n",
    "\n",
    "1. XML-Dokument herunterladen (mit `requests`-Library oder `urllib`-Library)\n",
    "2. Text (Inhalt von `<text>`-TEI-Element) mit `etree` aus Datei extrahieren:\n",
    "   - mit XML-Parser über das XML-File iterieren (Namespace des TEI-Wurzelelements berücksichtigen!)\n",
    "   -  Verwendung von Text-Extractor-Klasse (`TreeExtractor`; alternativ mit Funktionsaufruf: `gather_text`) und Hilfsfunktionen (`append_text`)\n",
    "3. Satzsegmentierung(mit `NLTK.sent_tokenize()` und POS-Tagging (hier mit `spacy`)\n",
    "4. Aufbau der neuen XML-Struktur mit `etree` (Satz-Segment- und Wort-POS-Informationen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb8e7c",
   "metadata": {},
   "source": [
    "#### TEI-XML-Grundstruktur (Altmann-BSP):\n",
    "```xml\n",
    "<TEI xmlns=\"http://www.tei-c.org/ns/1.0\">\n",
    "    <teiHeader>\n",
    "        ...\n",
    "    </teiHeader>\n",
    "    <text>\n",
    "        <front>\n",
    "            <titlePage type=\"halftitle\">\n",
    "                ...\n",
    "            </titlePage>\n",
    "        </front>\n",
    "        <body>\n",
    "            <div n=\"1\">\n",
    "                ...\n",
    "                <p>\n",
    "                    Seitdem von\n",
    "                    <hi rendition=\"#k\">Dujardin</hi>\n",
    "                    die contraktile Substanz oder Sar¬\n",
    "                    <lb/>\n",
    "                    kode entdeckt war, hat dieselbe in Bezug auf die Deutung ihres\n",
    "                    <lb/>\n",
    "                    ...\n",
    "                </p>\n",
    "            </div>\n",
    "        </body>\n",
    "        <back>\n",
    "            ...\n",
    "        </back>\n",
    "    </text>\n",
    "</TEI>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d5be4",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. append_text\n",
    "\n",
    "- Hilfsfunktion zur Konkatenation von bereits gelesenem Text in der XML-Datei mit neu eingelesenem Text\n",
    "- setzt getrennte Wörter am Zeilenende (`¬</lb>`) zusammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601d3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<abc def>>\n",
      "<<ungelegen>>\n"
     ]
    }
   ],
   "source": [
    "def append_text(text, str):\n",
    "    if not str or str == \"\":\n",
    "        return text \n",
    "    \n",
    "    str = str.strip()\n",
    "    if text == \"\":\n",
    "        return str \n",
    "    if text[-1] == '¬': # Trennerzeichen in XML-File\n",
    "        return text[:-1] + str \n",
    "    return text + \" \" + str \n",
    "\n",
    "print(f'<<{append_text(\"abc\", \"   def \")}>>')\n",
    "print(f'<<{append_text(\"unge¬\", \"legen\")}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e2444",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Textextraktion mit Klasse `TextExtractor`\n",
    "\n",
    "- Klasse zur Extraktion von Texts aus XML-Datei\n",
    "- verwendet append_text in rekursiver Iteration über die Kinderknoten   \n",
    "- erwartet root-ET-Objekt (z.B. `<text>`-Element im TEI-XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888a4e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def extract(self):\n",
    "        self.text = \"\"\n",
    "        self.extract_rec(self.root) #Iterieren über Kinderknoten mit rekursiver Funktion\n",
    "        return self.text\n",
    "        \n",
    "    def extract_rec(self, node):\n",
    "        self.text = append_text(self.text, node.text)\n",
    "        for c in node:  #Iterieren über Kinderknoten\n",
    "            self.extract_rec(c) #rekursiver Aufruf (für Extraktion des Texts aus Kinder-Knoten)\n",
    "        self.text = append_text(self.text, node.tail) #tail für Elemente vor dem schließenden Tag (im BSP: 4 und 5)\n",
    "        \n",
    "e = TextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d650295",
   "metadata": {},
   "source": [
    "#### Erläuterung: ohne append_text von node.tail (letzte Zeile in extract_rec) wird der Text vor dem schließenden Element nicht extrahiert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "829d81ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class TextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def extract(self):\n",
    "        self.text = \"\"\n",
    "        self.extract_rec(self.root)\n",
    "        return self.text\n",
    "        \n",
    "    def extract_rec(self, node):\n",
    "        self.text = append_text(self.text, node.text)\n",
    "        for c in node:\n",
    "            self.extract_rec(c)\n",
    "        #self.text = append_text(self.text, node.tail) #   <<<<<ohne tail: 3, 4 und 5 im BSP werden nicht extrahiert!\n",
    "\n",
    "e = TextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cda990",
   "metadata": {},
   "source": [
    "### Alternativer `IterTextExtractor`\n",
    "\n",
    "Verwendung von `itertext()` in Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1859306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "class IterTextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root \n",
    "        \n",
    "    def iter_extract(self):\n",
    "        self.text = \"\"\n",
    "        for c in self.root.itertext():\n",
    "            self.text = append_text(self.text, c)\n",
    "        return self.text\n",
    "\n",
    "e = IterTextExtractor(ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>'))\n",
    "print(f'<<{e.iter_extract()}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704a549",
   "metadata": {},
   "source": [
    "### Alternative Textextraktionsfunktion: `gather_text()` \n",
    "\n",
    "Funktion statt Klasse (Verwendung siehe xmlpos_spacy.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cff6fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<1 2 3 4 5>>\n"
     ]
    }
   ],
   "source": [
    "def gather_text(node, text):\n",
    "    text = append_text(text, node.text)\n",
    "    for c in node: #Iterieren über Kinder-Knoten\n",
    "        text = gather_text(c, text) #rekursiver Aufruf\n",
    "    #return text\n",
    "    return append_text(text, node.tail)\n",
    "\n",
    "root = ET.fromstring('<a><b>1<c>2<d/>3</c></b>4<lb/>5</a>')\n",
    "text = gather_text(root, \"\")\n",
    "print(f'<<{text}>>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8907e5",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Download der XML-Dateien und Verwendung der TextExtractor-Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44bc398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zu sichern. Das Bewusstsein, dass uns hier die Grundprobleme der Biologie berühren, wird es hoffen\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "import urllib.request\n",
    "url = \"https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890\"\n",
    "# url = \"https://www.deutschestextarchiv.de/book/download_xml/brandes_naturlehre03_1832\"\n",
    "\n",
    "\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    root = ET.fromstring(f.read())\n",
    "\n",
    "# TEI-Namespace (Namespace als Präfix der Elementnamen, z.B. http://www.tei-c.org/ns/1.0:element)\n",
    "ns = {'tei': 'http://www.tei-c.org/ns/1.0'} #Namespace-Dictionary mit Abkürzungen\n",
    "\n",
    "# Extraktion mit <tei:text> als Wurzelknoten (d.h. ohne Metadaten in <teiHeader>):\n",
    "e = TextExtractor(root.find('tei:text', ns))\n",
    "text = e.extract()\n",
    "print(text[1002:1100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cf341",
   "metadata": {},
   "source": [
    "### 4. Download des [Spacy](https://spacy.io) Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f980e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e6675",
   "metadata": {},
   "source": [
    "### 5. Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a70132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install --upgrade pip spacy\n",
    "import spacy\n",
    "#!{sys.executable} -m pip install --upgrade pip nltk\n",
    "from nltk import sent_tokenize\n",
    "import xml.dom.minidom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfc31d",
   "metadata": {},
   "source": [
    "### 6. POS-Tagging mit spaCy und Aufbau des XML-Baums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23941535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?>\n",
      "<doc>\n",
      "\t<s id=\"s-00001\">\n",
      "\t\t<w id=\"w-00001\" pos=\"DET\">DIE</w>\n",
      "\t\t<w id=\"w-00002\" pos=\"NOUN\">ELEMENTARORGANISMEN</w>\n",
      "\t\t<w id=\"w-00003\" pos=\"PROPN\">BEZIEHUNGEN</w>\n",
      "\t\t<w id=\"w-00004\" pos=\"ADP\">ZU</w>\n",
      "\t\t<w id=\"w-00005\" pos=\"PROPN\">DEN</w>\n",
      "\t\t<w id=\"w-00006\" pos=\"PROPN\">ZELLEN</w>\n",
      "\t\t<w id=\"w-00007\" pos=\"ADP\">VON</w>\n",
      "\t\t<w id=\"w-00008\" pos=\"SPACE\"> </w>\n",
      "\t\t<w id=\"w-00009\" pos=\"PROPN\">RICHARD</w>\n",
      "\t\t<w id=\"w-00010\" pos=\"PROPN\">ALTMANN</w>\n",
      "\t\t<w id=\"w-00011\" pos=\"PROPN\">MIT</w>\n",
      "\t\t<w id=\"w-00012\" pos=\"PROPN\">ZWEI</w>\n",
      "\t\t<w id=\"w-00013\" pos=\"PROPN\">ABBILDUNGEN</w>\n",
      "\t\t<w id=\"w-00014\" pos=\"ADP\">IM</w>\n",
      "\t\t<w id=\"w-00015\" pos=\"PROPN\">TEXT</w>\n",
      "\t\t<w id=\"w-00016\" pos=\"CCONJ\">UND</w>\n",
      "\t\t<w id=\"w-00017\" pos=\"PROPN\">XXI</w>\n",
      "\t\t<w id=\"w-00018\" pos=\"PROPN\">TAFELN</w>\n",
      "\t\t<w id=\"w-00019\" pos=\"PUNCT\">.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00002\">\n",
      "\t\t<w id=\"w-00020\" pos=\"PROPN\">LEIPZIG</w>\n",
      "\t\t<w id=\"w-00021\" pos=\"PUNCT\">,</w>\n",
      "\t\t<w id=\"w-00022\" pos=\"PROPN\">VERLAG</w>\n",
      "\t\t<w id=\"w-00023\" pos=\"PROPN\">VON</w>\n",
      "\t\t<w id=\"w-00024\" pos=\"PROPN\">VEIT</w>\n",
      "\t\t<w id=\"w-00025\" pos=\"CCONJ\">&amp;</w>\n",
      "\t\t<w id=\"w-00026\" pos=\"PROPN\">COMP</w>\n",
      "\t\t<w id=\"w-00027\" pos=\"PUNCT\">.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00003\">\n",
      "\t\t<w id=\"w-00028\" pos=\"NUM\">1890.</w>\n",
      "\t</s>\n",
      "\t<s id=\"s-00004\">\n",
      "\t\t<w id=\"w-00029\" pos=\"DET\">DIE</w>\n",
      "\t\t<w id=\"w-00030\" pos=\"NOUN\">ELEMENTARORGANISMEN</w>\n",
      "\t\t<w id=\"w-00031\" pos=\"PROPN\">BEZIEHUNGEN</w>\n",
      "\t\t<w id=\"w-00032\" pos=\"ADP\">ZU</w>\n",
      "\t\t<w id=\"w-00033\" pos=\"PROPN\">DEN</w>\n",
      "\t\t<w id=\"w-00034\" pos=\"PROPN\">ZELLEN</w>\n",
      "\t\t<w id=\"w-00035\" pos=\"PUNCT\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('de_core_news_sm')\n",
    "out = ET.Element('doc') #für Erzeugung XML-File\n",
    "sid = 1 # sentence id\n",
    "wid = 1 # word id\n",
    "\n",
    "#Satzsegmentierung mit NLTK-Methode:\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "#POS-Tagging mit spaCy und Erzeugung XML-File:\n",
    "for sent in sents:\n",
    "    stag = ET.SubElement(out, 's') #Erzeugung von s-Element\n",
    "    stag.attrib = {'id': f's-{sid:05d}'}\n",
    "    sid += 1\n",
    "    tokens = nlp(sent) #Analyse mit spaCy\n",
    "    for token in tokens: #Erzeugen von w-Elementen (pro Satz)\n",
    "        wtag = ET.SubElement(stag, 'w')\n",
    "        wtag.text = token.text\n",
    "        wtag.attrib = {'pos': token.pos_, 'id': f'w-{wid:05d}'}\n",
    "        wid += 1\n",
    "\n",
    "dom = xml.dom.minidom.parseString(ET.tostring(out))\n",
    "print(dom.toprettyxml()[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617bce8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Usage von xmlpos_spacy.py:\n",
    "\n",
    "#### Einlesen aus XML-Datei, Tagging und Transformation mit xmlpos_spacy.py, Ausgabe in neue XML-Datei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "805a35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat altmann_elementarorganismen_1890.TEI-P5.xml | python3 xmlpos_spacy.py > altmann_elementarorganismen_1890_spacy.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28af6e",
   "metadata": {},
   "source": [
    "#### Formatierte Ausgabe XML auf Kommandozeile mit xmllint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "963db56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<doc>\n",
      "  <s id=\"s-1\">\n",
      "    <w pos=\"DET\" id=\"w-1\">DIE</w>\n",
      "    <w pos=\"SPACE\" id=\"w-2\"> </w>\n",
      "    <w pos=\"NOUN\" id=\"w-3\">ELEMENTARORGANISMEN</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-4\">UND</w>\n",
      "    <w pos=\"PROPN\" id=\"w-5\">IHRE</w>\n",
      "    <w pos=\"SPACE\" id=\"w-6\"> </w>\n",
      "    <w pos=\"PROPN\" id=\"w-7\">BEZIEHUNGEN</w>\n",
      "    <w pos=\"NOUN\" id=\"w-8\">ZU</w>\n",
      "    <w pos=\"PROPN\" id=\"w-9\">DEN</w>\n",
      "    <w pos=\"PROPN\" id=\"w-10\">ZELLEN</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-11\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-2\">\n",
      "    <w pos=\"ADP\" id=\"w-12\">VON</w>\n",
      "    <w pos=\"SPACE\" id=\"w-13\">  </w>\n",
      "    <w pos=\"X\" id=\"w-14\">RICHARD</w>\n",
      "    <w pos=\"PROPN\" id=\"w-15\">ALTMANN</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-16\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-3\">\n",
      "    <w pos=\"ADP\" id=\"w-17\">MIT</w>\n",
      "    <w pos=\"ADV\" id=\"w-18\">ZWEI</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_spacy.xml | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c8818a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  <s id=\"s-12\">\n",
      "    <w pos=\"NOUN\" id=\"w-82\">Vorbemerkung</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-83\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-13\">\n",
      "    <w pos=\"DET\" id=\"w-84\">Die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-85\">nachfolgenden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-86\">Capitel</w>\n",
      "    <w pos=\"VERB\" id=\"w-87\">enthalten</w>\n",
      "    <w pos=\"ADP\" id=\"w-88\">im</w>\n",
      "    <w pos=\"NOUN\" id=\"w-89\">Wesentlichen</w>\n",
      "    <w pos=\"DET\" id=\"w-90\">eine</w>\n",
      "    <w pos=\"NOUN\" id=\"w-91\">theils</w>\n",
      "    <w pos=\"VERB\" id=\"w-92\">erweiterte</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-93\">,</w>\n",
      "    <w pos=\"ADV\" id=\"w-94\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-95\">verk&#xFC;rzte</w>\n",
      "    <w pos=\"NOUN\" id=\"w-96\">Zusammenstellung</w>\n",
      "    <w pos=\"DET\" id=\"w-97\">derjenigen</w>\n",
      "    <w pos=\"NOUN\" id=\"w-98\">Abhandlungen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-99\">,</w>\n",
      "    <w pos=\"PRON\" id=\"w-100\">welche</w>\n",
      "    <w pos=\"ADV\" id=\"w-101\">bisher</w>\n",
      "    <w pos=\"ADP\" id=\"w-102\">von</w>\n",
      "    <w pos=\"PRON\" id=\"w-103\">mir</w>\n",
      "    <w pos=\"ADP\" id=\"w-104\">&#xFC;ber</w>\n",
      "    <w pos=\"DET\" id=\"w-105\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-106\">Zellengranula</w>\n",
      "    <w pos=\"VERB\" id=\"w-107\">ver&#xF6;ffentlicht</w>\n",
      "    <w pos=\"AUX\" id=\"w-108\">worden</w>\n",
      "    <w pos=\"AUX\" id=\"w-109\">sind</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-110\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-14\">\n",
      "    <w pos=\"SCONJ\" id=\"w-111\">Indem</w>\n",
      "    <w pos=\"ADV\" id=\"w-112\">hierzu</w>\n",
      "    <w pos=\"DET\" id=\"w-113\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-114\">Beschreibung</w>\n",
      "    <w pos=\"DET\" id=\"w-115\">der</w>\n",
      "    <w pos=\"NOUN\" id=\"w-116\">Methoden</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-117\">und</w>\n",
      "    <w pos=\"DET\" id=\"w-118\">die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-119\">erl&#xE4;uternden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-120\">Abbildungen</w>\n",
      "    <w pos=\"VERB\" id=\"w-121\">kommen</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_spacy.xml | sed -n '106,150p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6108b8",
   "metadata": {},
   "source": [
    "#### Alternatives Herunterladen der XML-Datei mit curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7386ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      " 22  385k   22 90112    0     0  49558      0  0:00:07  0:00:01  0:00:06 49539\r\n",
      "100  385k  100  385k    0     0   202k      0  0:00:01  0:00:01 --:--:--  202k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl https://www.deutschestextarchiv.de/book/download_xml/altmann_elementarorganismen_1890 | python3 xmlpos_spacy.py > altmann_elementarorganismen_1890_spacy.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39224519",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgabe 2: Variante POS-Tagging mit stanza\n",
    "\n",
    "- Abschließend wird hier noch eine Variante gezeigt, die stanza statt spaCy zum POS-Tagging verwendet\n",
    "- auch zur Satzsegmentierung wird hier stanza verwendet\n",
    "\n",
    "\n",
    "- MWT (Multi-Word Token Expansion) in Pipeline führt zu Abweichungen vom Originaltext, wenn man die über die words iteriert und diese ausgibt\n",
    "  - da z.B. *zum* zu *zu* *dem* transformiert wird\n",
    "- stattdessen muss über die tokens iteriert werden und POS-Infos aus den words eines token extrahiert werden\n",
    "- vgl. https://stanfordnlp.github.io/stanza/mwt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7014",
   "metadata": {},
   "source": [
    "#### xmlpos_stanza.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xml.etree.ElementTree as ET \n",
    "import stanza\n",
    "\n",
    "\n",
    "def append_text(text, str):\n",
    "    if not str or str == \"\":\n",
    "        return text \n",
    "    \n",
    "    str = str.strip()\n",
    "    if text == \"\":\n",
    "        return str \n",
    "    if text[-1] == '¬':\n",
    "        return text[:-1] + str \n",
    "    return text + \" \" + str \n",
    "\n",
    "\n",
    "def gather_text(node, text):\n",
    "    text = append_text(text, node.text)\n",
    "    for c in  node:\n",
    "        text = gather_text(c, text)\n",
    "    return append_text(text, node.tail)\n",
    "    \n",
    "\n",
    "root = ET.fromstring(sys.stdin.read())    \n",
    "out = ET.Element('doc')\n",
    "nlp = stanza.Pipeline(lang='de', processors='tokenize, pos', download_method=None) #stanza-Pipeline\n",
    "sid = 1 \n",
    "tid = 1\n",
    "text = gather_text(root, \"\")\n",
    "\n",
    "for t in root.iter('{http://www.tei-c.org/ns/1.0}text'):\n",
    "    text = gather_text(t, \"\")\n",
    "    \n",
    "    doc = nlp(text)  #POS-Annotation mit stanza\n",
    "    sents = doc.sentences  #Tokenisierung: hier mit stanza statt NLTK.sent_tokenize\n",
    "    for sent in sents: \n",
    "        stag = ET.SubElement(out, 's')\n",
    "        stag.attrib = {'id': f\"s-{sid}\"}\n",
    "        sid += 1\n",
    "        \n",
    "        tokens = sent.tokens #stanza-Methode .tokens (statt .words, wegen MWT)\n",
    "        for token in tokens:\n",
    "            ttag = ET.SubElement(stag, 'w')\n",
    "            ttag.text = token.text\n",
    "            word_upos = \"+\".join([word.upos for word in token.words]) #join der durch MWT von stanza getrennt analysierten word-POS-tags\n",
    "            ttag.attrib = {'pos': word_upos, 'id': f\"w-{tid}\"}  #stanza\n",
    "            tid += 1 \n",
    "ET.dump(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d60ccf",
   "metadata": {},
   "source": [
    "#### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a265db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:49 WARNING: Language de package default expects mwt, which has been added\n",
      "2023-06-29 12:08:49 INFO: Loading these models for language: de (German):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-06-29 12:08:49 INFO: Using device: cpu\n",
      "2023-06-29 12:08:49 INFO: Loading: tokenize\n",
      "2023-06-29 12:08:49 INFO: Loading: mwt\n",
      "2023-06-29 12:08:49 INFO: Loading: pos\n",
      "2023-06-29 12:08:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat altmann_elementarorganismen_1890.TEI-P5.xml | python3 xmlpos_stanza.py > altmann_elementarorganismen_1890_stanza.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98480daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  <s id=\"s-10\">\n",
      "    <w pos=\"NOUN\" id=\"w-75\">Vorbemerkung</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-76\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-11\">\n",
      "    <w pos=\"DET\" id=\"w-77\">Die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-78\">nachfolgenden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-79\">Capitel</w>\n",
      "    <w pos=\"VERB\" id=\"w-80\">enthalten</w>\n",
      "    <w pos=\"ADP+DET\" id=\"w-81\">im</w>\n",
      "    <w pos=\"NOUN\" id=\"w-82\">Wesentlichen</w>\n",
      "    <w pos=\"DET\" id=\"w-83\">eine</w>\n",
      "    <w pos=\"ADV\" id=\"w-84\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-85\">erweiterte</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-86\">,</w>\n",
      "    <w pos=\"ADV\" id=\"w-87\">theils</w>\n",
      "    <w pos=\"ADJ\" id=\"w-88\">verk&#xFC;rzte</w>\n",
      "    <w pos=\"NOUN\" id=\"w-89\">Zusammenstellung</w>\n",
      "    <w pos=\"PRON\" id=\"w-90\">derjenigen</w>\n",
      "    <w pos=\"NOUN\" id=\"w-91\">Abhandlungen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-92\">,</w>\n",
      "    <w pos=\"PRON\" id=\"w-93\">welche</w>\n",
      "    <w pos=\"ADV\" id=\"w-94\">bisher</w>\n",
      "    <w pos=\"ADP\" id=\"w-95\">von</w>\n",
      "    <w pos=\"PRON\" id=\"w-96\">mir</w>\n",
      "    <w pos=\"ADP\" id=\"w-97\">&#xFC;ber</w>\n",
      "    <w pos=\"DET\" id=\"w-98\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-99\">Zellengranula</w>\n",
      "    <w pos=\"VERB\" id=\"w-100\">ver&#xF6;ffentlicht</w>\n",
      "    <w pos=\"AUX\" id=\"w-101\">worden</w>\n",
      "    <w pos=\"AUX\" id=\"w-102\">sind</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-103\">.</w>\n",
      "  </s>\n",
      "  <s id=\"s-12\">\n",
      "    <w pos=\"SCONJ\" id=\"w-104\">Indem</w>\n",
      "    <w pos=\"ADV\" id=\"w-105\">hierzu</w>\n",
      "    <w pos=\"DET\" id=\"w-106\">die</w>\n",
      "    <w pos=\"NOUN\" id=\"w-107\">Beschreibung</w>\n",
      "    <w pos=\"DET\" id=\"w-108\">der</w>\n",
      "    <w pos=\"NOUN\" id=\"w-109\">Methoden</w>\n",
      "    <w pos=\"CCONJ\" id=\"w-110\">und</w>\n",
      "    <w pos=\"DET\" id=\"w-111\">die</w>\n",
      "    <w pos=\"ADJ\" id=\"w-112\">erl&#xE4;uternden</w>\n",
      "    <w pos=\"NOUN\" id=\"w-113\">Abbildungen</w>\n",
      "    <w pos=\"VERB\" id=\"w-114\">kommen</w>\n",
      "    <w pos=\"PUNCT\" id=\"w-115\">,</w>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "xmllint --format altmann_elementarorganismen_1890_stanza.xml | sed -n '95,140p'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
