{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsaufgaben 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: xmltcf (Verarbeitung von annotierten XML-Dateien im TCF-Format)\n",
    "\n",
    "Im deutschen Textarchiv findet man auch annotierte Daten zu den\n",
    "entsprechenden Dokumenten.  Laden Sie eine solche lemmatisierte und\n",
    "annotierte XML-Datei im [TCF-Format](https://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/The_TCF_Format) (Text Corpus Format)\n",
    "herunter (z.B. Altmann: https://www.deutschestextarchiv.de/book/download_fulltcf/16299)\n",
    "und schreiben Sie ein Programm `xmltcf`, das eine zeilenweise die Sätze\n",
    "ausgibt, wobei die Token entweder mit ihren Lemmata oder ihren Tags\n",
    "annotiert sind:\n",
    "```bash\n",
    "$ ./xmltcf.py file.xml\n",
    "Ich/ich gehe/gehen ...\n",
    "$ ./xmltcf.py --tags file.xml\n",
    "Der/DET Mann/NOUN ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorgehen:\n",
    "\n",
    "- Iterieren über Sätze (`<sentences>`) und Tokens (`<tokens>`) des TCF-XML-Files\n",
    "- Lookup von POS (`<POStags>`) und Lemmata (`<lemmas>`) im XML über `tokenIDs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCF-XML-Grundstruktur:\n",
    "```xml\n",
    "<D-Spin xmlns=\"http://www.dspin.de/data\" version=\"0.4\">\n",
    "    <MetaData xmlns=\"http://www.dspin.de/data/metadata\">\n",
    "        ...\n",
    "    </MetaData>\n",
    "    <TextCorpus  xmlns=\"http://www.dspin.de/data/textcorpus\" lang=\"de\">\n",
    "        <tokens>\n",
    "            <token ID=\"w1\">zwei</token>\n",
    "            <token ID=\"w2\">Tests</token>\n",
    "        </tokens>\n",
    "        <sentences>\n",
    "            <sentence ID=\"s1\" tokenIDs=\"w1 w2\"/>\n",
    "        </sentences>\n",
    "        <lemmas>\n",
    "            <lemma tokenIDs=\"w1\">zwei</lemma>\n",
    "            <lemma tokenIDs=\"w2\">Test</lemma>\n",
    "        </lemmas>\n",
    "        <POStags tagset=\"stts\">\n",
    "            <tag tokenIDs=\"w1\">ART</tag>\n",
    "            <tag tokenIDs=\"w2\">NN</tag>\n",
    "        </POStags>\n",
    "        <orthography>\n",
    "            ...\n",
    "        </orthography>\n",
    "    </TextCorpus>\n",
    "</D-Spin>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xmltcf.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "\n",
    "# Token-Daten-Klasse: speichert Token, ID, POS-Tag und Lemma\n",
    "class Token:\n",
    "    def __init__(self, word, id, tag=None, lemma=None):\n",
    "        self.word = word\n",
    "        self.id = id\n",
    "        self.tag = tag\n",
    "        self.lemma = lemma\n",
    "\n",
    "# url = 'https://www.deutschestextarchiv.de/book/download_fulltcf/16299'\n",
    "\n",
    "def parse_xml(url, tags):\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        root = ET.fromstring(f.read())\n",
    "\n",
    "#    with open(name, encoding='utf-8') as f:\n",
    "#        root = ET.fromstring(f.read())\n",
    "        \n",
    "    #Namespace-Dictionary (TextCorpus-Namespace):\n",
    "    ns = {'tc': \"http://www.dspin.de/data/textcorpus\"} \n",
    "    \n",
    "    #1. Iterieren über Token-Elemente im TextCorpus-Knoten, Generierung lex-Dictionary mit Tokens+IDs:\n",
    "    # (Verwendung von Token-Datenklasse (oben definiert) in Dictionary-Comprehension)\n",
    "    lex = {t.attrib[\"ID\"]: Token(t.text, t.attrib[\"ID\"]) for t in root.find('tc:TextCorpus', ns).find('tc:tokens', ns)}\n",
    "\n",
    "    #2. Iterieren über Lemmas- und POSTags-Elemente und Ergänzung in lex-Dictionary (über tokenIDs):\n",
    "    for lemma in root.find('tc:TextCorpus', ns).find('tc:lemmas', ns ):\n",
    "        token = lex[lemma.attrib[\"tokenIDs\"]]\n",
    "        token.lemma = lemma.text\n",
    "    for tag in root.find('tc:TextCorpus', ns ).find('tc:POStags', ns):\n",
    "        token = lex[tag.attrib[\"tokenIDs\"]]\n",
    "        token.tag = tag.text\n",
    "        \n",
    "    # lex-Dictionary enthält für jede Token-ID: word, id, pos-tag, lemma\n",
    "\n",
    "    #3. Iterieren über sentences-Knoten und satzweises Erzeugen von \"Token/Tag\"- bzw. \"Token/Lemma\"-Strings: \n",
    "    # (Lookup in lex-Dictionary über tokenIDs)\n",
    "    #(in Abhängigkeit von argparse-Option -t = tags bei Ausführung):\n",
    "    for sent in root.find('tc:TextCorpus', ns).find('tc:sentences', ns):\n",
    "        if tags:\n",
    "            print(\" \".join([lex[id].word + \"/\" + lex[id].tag for id in sent.attrib[\"tokenIDs\"].split(\" \")]))\n",
    "        else:\n",
    "            print(\" \".join([lex[id].word + \"/\" + lex[id].lemma for id in sent.attrib[\"tokenIDs\"].split(\" \")]))\n",
    "\n",
    "\n",
    "# Argumente für Programmaufruf über Kommandozeile (inklusive Help-Option):\n",
    "parser = argparse.ArgumentParser(description='write tokens with their tags or lemmas from tcf files')\n",
    "parser.add_argument('-t', '--tags', help='output tokens with their tag instead of their lemma', action=\"store_true\")\n",
    "parser.add_argument('urls', help='list of urls to operate on', nargs='*')\n",
    "\n",
    "args = parser.parse_args()\n",
    "for url in args.urls:\n",
    "    parse_xml(url, args.tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: xmltcf.py [-h] [-t] [urls [urls ...]]\n",
      "\n",
      "write tokens with their tags or lemmas from tcf files\n",
      "\n",
      "positional arguments:\n",
      "  urls        list of urls to operate on\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n",
      "  -t, --tags  output tokens with their tag instead of their lemma\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./xmltcf.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ausgabe Sätze mit POS-Tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./xmltcf.py -t https://www.deutschestextarchiv.de/book/download_fulltcf/16299 > sents.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIE/ART ELEMENTARORGANISMEN/NN UND/KON IHRE/ADJA BEZIEHUNGEN/NN ZU/APPR DEN/ART ZELLEN/NN ./$. VON/NN RICHARD/NE ALTMANN/NE ./$.\n",
      "MIT/NE ZWEI/ADJA ABBILDUNGEN/NN IM/APPR TEXT/NE UND/KON XXI/NE TAFELN./NE LEIPZIG/NE ,/$, VERLAG/NN VON/NE VEIT/NE &/$( COMP./NE 1890/CARD ./$.\n",
      "DIE/ART ELEMENTARORGANISMEN/NN UND/KON IHRE/ADJA BEZIEHUNGEN/NN ZU/APPR DEN/ART ZELLEN/NN ./$. VON/NN RICHARD/NE ALTMANN/NE ./$.\n",
      "MIT/NE ZWEI/ADJA ABBILDUNGEN/NN IM/APPR TEXT/NE UND/KON XXI/NE TAFELN./NE LEIPZIG/NE ,/$, VERLAG/NN VON/NE VEIT/NE &/$( COMP./NE 1890/CARD ./$.\n",
      "HERRN/NN WILHELM/NE HIS/NE IN/APPR DANKBARER/ADJA VEREHRUNG/NN GEWIDMET/VVPP VOM/ADJA VERFASSER/NN ./$.\n",
      "Vorbemerkung/NN ./$.\n",
      "Die/ART nachfolgenden/ADJA Capitel/NN enthalten/VVFIN im/APPRART Wesentlichen/NN eine/ART theils/ADV erweiterte/ADJA ,/$, theils/ADV verkürzte/ADJA Zusammenstellung/NN derjenigen/PDS Abhandlungen/NN ,/$, welche/PRELS bisher/ADV von/APPR mir/PPER über/APPR die/ART Zellengranula/NN veröffentlicht/VVPP worden/VAPP sind/VAFIN ./$.\n",
      "Indem/KOUS hierzu/PAV die/ART Beschreibung/NN der/ART Methoden/NN und/KON die/ART erläuternden/ADJA Abbildungen/NN kommen/VVFIN ,/$, dürfte/VMFIN das/ART Ganze/NN wohl/ADV geeignet/VVPP sein/VAINF ,/$, den/ART jetzigen/ADJA Standpunkt/NN der/ART Granulafrage/NN zu/PTKZU zeigen/VVINF ./$.\n",
      "So/ADV unvollkommen/ADJD dieser/PDAT Standpunkt/NN auch/ADV noch/ADV sein/VAINF mag/VMFIN ,/$, so/ADV liegt/VVFIN wohl/ADV immerhin/ADV schon/ADV ein/ART genügendes/ADJA Material/NN vor/PTKVZ ,/$, um/KOUI das/ART Geschick/NN jener/PDAT Lehre/NN für/APPR die/ART Zukunft/NN zu/APPR sichern/ADJA ./$.\n",
      "Das/ART Bewusstsein/NN ,/$, dass/KOUS uns/PPER hier/ADV die/ART Grundprobleme/NN der/ART Biologie/NN berühren/VVINF ,/$, wird/VAFIN es/PPER hoffentlich/ADJD herbeiführen/VVINF ,/$, dass/KOUS jener/PDAT Frage/NN sachliche/ADJA Mitarbeiter/NN gewonnen/VVPP werden/VAINF ,/$, denn/KON die/ART Kraft/NN des/ART Einzelnen/NN ist/VAFIN zu/PTKA gering/ADJD ,/$, um/KOUI den/ART hier/ADV vorhandenen/ADJA Anforderungen/NN zu/PTKZU genügen/VVINF ./$.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sed 10q sents.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ausgabe Sätze mit Lemmata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./xmltcf.py https://www.deutschestextarchiv.de/book/download_fulltcf/16299 > sents_lemmata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIE/d ELEMENTARORGANISMEN/Elementarorganismus UND/und IHRE/Ihre BEZIEHUNGEN/Beziehung ZU/zu DEN/d ZELLEN/Zelle ./. VON/VON RICHARD/Richard ALTMANN/Altmann ./.\n",
      "MIT/Massachussetts_Institute_Of_Technology ZWEI/zwei ABBILDUNGEN/Abbildung IM/IM TEXT/Text UND/und XXI/Xxi TAFELN./TAFELN. LEIPZIG/Leipzig ,/, VERLAG/Verlag VON/VON VEIT/Veit &/& COMP./COMP. 1890/1890 ./.\n",
      "DIE/d ELEMENTARORGANISMEN/Elementarorganismus UND/und IHRE/Ihre BEZIEHUNGEN/Beziehung ZU/zu DEN/d ZELLEN/Zelle ./. VON/VON RICHARD/Richard ALTMANN/Altmann ./.\n",
      "MIT/Massachussetts_Institute_Of_Technology ZWEI/zwei ABBILDUNGEN/Abbildung IM/IM TEXT/Text UND/und XXI/Xxi TAFELN./TAFELN. LEIPZIG/Leipzig ,/, VERLAG/Verlag VON/VON VEIT/Veit &/& COMP./COMP. 1890/1890 ./.\n",
      "HERRN/Herr WILHELM/Wilhelm HIS/His IN/in DANKBARER/dankbar VEREHRUNG/Verehrung GEWIDMET/widmen VOM/vom VERFASSER/Verfasser ./.\n",
      "Vorbemerkung/Vorbemerkung ./.\n",
      "Die/d nachfolgenden/nachfolgend Capitel/Kapitel enthalten/enthalten im/im Wesentlichen/Wesentliche eine/eine theils/teils erweiterte/erweitert ,/, theils/teils verkürzte/verkürzt Zusammenstellung/Zusammenstellung derjenigen/diejenige Abhandlungen/Abhandlung ,/, welche/welche bisher/bisher von/von mir/ich über/über die/d Zellengranula/Zellengranulum veröffentlicht/veröffentlichen worden/werden sind/sein ./.\n",
      "Indem/indem hierzu/hierzu die/d Beschreibung/Beschreibung der/d Methoden/Methode und/und die/d erläuternden/erläuternd Abbildungen/Abbildung kommen/kommen ,/, dürfte/dürfen das/d Ganze/Ganze wohl/wohl geeignet/eignen sein/sein ,/, den/d jetzigen/jetzig Standpunkt/Standpunkt der/d Granulafrage/Granulumfrage zu/zu zeigen/zeigen ./.\n",
      "So/so unvollkommen/unvollkommen dieser/diese Standpunkt/Standpunkt auch/auch noch/noch sein/sein mag/mögen ,/, so/so liegt/liegen wohl/wohl immerhin/immerhin schon/schon ein/eine genügendes/genügend Material/Material vor/vor ,/, um/um das/d Geschick/Geschick jener/jen Lehre/Lehre für/für die/d Zukunft/Zukunft zu/zu sichern/sicher ./.\n",
      "Das/d Bewusstsein/Bewußtsein ,/, dass/dass uns/wir hier/hier die/d Grundprobleme/Grundproblem der/d Biologie/Biologie berühren/berühren ,/, wird/werden es/es hoffentlich/hoffentlich herbeiführen/herbeiführen ,/, dass/dass jener/jen Frage/Frage sachliche/sachlich Mitarbeiter/Mitarbeiter gewonnen/gewinnen werden/werden ,/, denn/denn die/d Kraft/Kraft des/d Einzelnen/Einzelne ist/sein zu/zu gering/gering ,/, um/um den/d hier/hier vorhandenen/vorhanden Anforderungen/Anforderung zu/zu genügen/genügen ./.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sed 10q sents_lemmata.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
